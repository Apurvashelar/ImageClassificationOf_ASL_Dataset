{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageClassificationOf_ASL_Dataset_using_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w381eQXU5U4"
      },
      "source": [
        "Image Classification of an American Sign Language Dataset using the concept of data augmentation and CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kSpwvPHVOR-"
      },
      "source": [
        "# Importing the libaries required\n",
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "\n",
        "# Load in our data from CSV files\n",
        "train_df = pd.read_csv(\"sign_mnist_train.csv\")\n",
        "valid_df = pd.read_csv(\"sign_mnist_valid.csv\")\n",
        "\n",
        "# Separate out the target values\n",
        "y_train = train_df['label']\n",
        "y_valid = valid_df['label']\n",
        "del train_df['label']\n",
        "del valid_df['label']\n",
        "\n",
        "# Separate out the image vectors\n",
        "x_train = train_df.values\n",
        "x_valid = valid_df.values\n",
        "\n",
        "# Turn the scalar targets into binary categories\n",
        "num_classes = 24\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)           # Encode the target values \n",
        "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
        "\n",
        "# Normalize the image data between 0 to 1\n",
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255\n",
        "\n",
        "# Reshape the image data for the convolutional network\n",
        "x_train = x_train.reshape(-1,28,28,1)                  # We need to convert the current shape (27455, 784) to (27455, 28, 28, 1). As a convenience, we can pass the reshape method a -1 for any dimension we wish to remain the same\n",
        "x_valid = x_valid.reshape(-1,28,28,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76RxTnC-WSxj"
      },
      "source": [
        "# CNN model architecture\n",
        "# Creating a convolutional model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Conv2D,\n",
        "    MaxPool2D,\n",
        "    Flatten,\n",
        "    Dropout,\n",
        "    BatchNormalization,\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\", \n",
        "                 input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=512, activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=num_classes, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epKWr0i_WxTn"
      },
      "source": [
        "# Data Augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,        # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    zoom_range=0.1,           # Randomly zoom image\n",
        "    width_shift_range=0.1,    # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,   # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,     # randomly flip images horizontally\n",
        "    vertical_flip=False,      # Don't randomly flip images vertically\n",
        ")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXPfndViXCfU"
      },
      "source": [
        "#batches our data using batch size of so that our model can train on a random sample.\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "batch_size = 32\n",
        "img_iter = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
        "\n",
        "x, y = img_iter.next()\n",
        "fig, ax = plt.subplots(nrows=4, ncols=8)\n",
        "for i in range(batch_size):\n",
        "    image = x[i]\n",
        "    ax.flatten()[i].imshow(np.squeeze(image))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TIwTawDZYyi"
      },
      "source": [
        "#Fitting the Data to the Generator Next, the generator must be fit on the training dataset.\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTQjBYsTZ2hv"
      },
      "source": [
        "model.fit(img_iter,\n",
        "          epochs=20,\n",
        "          steps_per_epoch=len(x_train)/batch_size, # Run same number of steps we would if we were not using a generator.\n",
        "          validation_data=(x_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2knESE3xax6_"
      },
      "source": [
        "# Save the trained model\n",
        "model.save('asl_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B1ppNsQjzYG"
      },
      "source": [
        "# Load the saved model\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.load_model('asl_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2SAAR76j7MV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def show_image(image_path):\n",
        "    image = mpimg.imread(image_path)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "\n",
        "show_image('b.png')    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiVw4XDQkGox"
      },
      "source": [
        "# Scaling the images\n",
        "# Pass the same size and grayscale images into our method for prediction\n",
        "\n",
        "from tensorflow.keras.preprocessing import image as image_utils\n",
        "\n",
        "def load_and_scale_image(image_path):\n",
        "    image = image_utils.load_img(image_path, color_mode=\"grayscale\", target_size=(28,28))\n",
        "    return image   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-peKE35kuDd"
      },
      "source": [
        "image = load_and_scale_image('b.png')\n",
        "plt.imshow(image, cmap='gray') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7leol-7ykus9"
      },
      "source": [
        "# Convert the test image into an array format\n",
        "image = image_utils.img_to_array(image)\n",
        "\n",
        "# Reshape the test image\n",
        "image = image.reshape(1,28,28,1) \n",
        "\n",
        "# Normalize the test image\n",
        "image = image / 255\n",
        "\n",
        "#Make predictions\n",
        "prediction = model.predict(image)\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsk16YR3lN3b"
      },
      "source": [
        "# Get the highest probability of the prediction\n",
        "import numpy as np\n",
        "np.argmax(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad0A1SWnlb-z"
      },
      "source": [
        "# Alphabet does not contain j or z because they require movement\n",
        "alphabet = \"abcdefghiklmnopqrstuvwxy\"\n",
        "dictionary = {}\n",
        "for i in range(24):\n",
        "    dictionary[i] = alphabet[i]\n",
        "dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA1hs2N9lfPB"
      },
      "source": [
        "dictionary[np.argmax(prediction)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CuyXhNmlnyy"
      },
      "source": [
        "# Put it all together\n",
        "def predict_letter(file_path):\n",
        "    show_image(file_path)\n",
        "    image = load_and_scale_image(file_path)\n",
        "    image = image_utils.img_to_array(image)\n",
        "    image = image.reshape(1,28,28,1) \n",
        "    image = image/255\n",
        "    prediction = model.predict(image)\n",
        "    \n",
        "    # convert prediction to letter\n",
        "    predicted_letter = dictionary[np.argmax(prediction)]\n",
        "    return predicted_letter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOQ01dwyl3AX"
      },
      "source": [
        "predict_letter(\"b.png\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}